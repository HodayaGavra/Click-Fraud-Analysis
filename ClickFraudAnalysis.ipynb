{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMuWfgF5mO4lOM/j1rsQ+CZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["#Example1: check whether the data follows a normal distribution while considering that most clicks occur during the day and fewer at night\n","\n","#It is assumed that each publisher's data is according to its time zone.\n","#you can perform a normality test and visually inspect the data using a histogram.\n","#It's important to keep in mind that click data might not follow a strict normal distribution due to diurnal patterns.\n","\n","import numpy as np\n","from scipy import stats\n","import matplotlib.pyplot as plt\n","import your_database_library  # Import database library (e.g., psycopg2, pymysql)\n","\n","# Define SQL query\n","query = \"\"\"\n","SELECT\n","    publisher_id,\n","    EXTRACT(HOUR FROM click_timestamp) AS hour_of_day,\n","    COUNT(*) AS clicks_per_hour\n","FROM\n","    your_clicks_table\n","GROUP BY\n","    publisher_id,\n","    hour_of_day\n","ORDER BY\n","    publisher_id,\n","    hour_of_day;\n","\"\"\"\n","\n","# Database connection parameters\n","db_params = {\n","    'host': 'your_host',\n","    'user': 'your_user',\n","    'password': 'your_password',\n","    'database': 'your_database'\n","}\n","\n","# Establish a database connection\n","try:\n","    connection = your_database_library.connect(**db_params)\n","\n","    # Execute the SQL query to get the data\n","    with connection.cursor() as cursor:\n","        cursor.execute(query)\n","        result = cursor.fetchall()\n","\n","    # Extract the 'clicks_per_hour' data into a NumPy array\n","    clicks_data = np.array([row[2] for row in result])\n","\n","    # Perform the Shapiro-Wilk normality test\n","    statistic, p_value = stats.shapiro(clicks_data)\n","\n","    # Create a histogram to visualize the distribution\n","    plt.hist(clicks_data, bins=20, density=True, alpha=0.6, color='b', label='Clicks per Hour')\n","    plt.xlabel('Number of Clicks')\n","    plt.ylabel('Frequency')\n","    plt.title('Clicks Distribution')\n","\n","    # Optionally, overlay a normal distribution curve for comparison\n","    mean, std_dev = np.mean(clicks_data), np.std(clicks_data)\n","    x = np.linspace(min(clicks_data), max(clicks_data), 100)\n","    pdf = stats.norm.pdf(x, mean, std_dev)\n","    plt.plot(x, pdf, 'k--', label='Normal Distribution')\n","\n","    plt.legend()\n","    plt.show()\n","\n","    # Check if the data follows a normal distribution\n","    alpha = 0.05  # Set your desired significance level\n","    if p_value > alpha:\n","        print(\"The data follows a normal distribution.\")\n","    else:\n","        print(\"The data does not follow a normal distribution\")\n","\n","finally:\n","    if connection:\n","        connection.close()\n"],"metadata":{"id":"7xBnMtfeI2KR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Example2: check whether we can find mulltiple clicks that occurred on the previous day identify by the same IP address and publisher.\n","\n","\n","from collections import defaultdict\n","from datetime import datetime, timedelta\n","\n","# Sample data with timestamp, IP addresses, and publisher_id\n","sample_data = [\n","    {\"timestamp\": \"2023-10-25 14:30:00\", \"ip\": \"192.168.1.1\", \"publisher_id\": 1},\n","    {\"timestamp\": \"2023-10-25 14:45:00\", \"ip\": \"192.168.1.2\", \"publisher_id\": 1},\n","    {\"timestamp\": \"2023-10-25 15:00:00\", \"ip\": \"192.168.1.1\", \"publisher_id\": 2},\n","    {\"timestamp\": \"2023-10-25 15:15:00\", \"ip\": \"192.168.1.1\", \"publisher_id\": 1},\n","    {\"timestamp\": \"2023-10-25 15:30:00\", \"ip\": \"192.168.1.2\", \"publisher_id\": 1},\n","    # Add more data entries here\n","]\n","\n","# Calculate the date for yesterday\n","yesterday = datetime.now() - timedelta(days=1)\n","yesterday_str = yesterday.strftime(\"%Y-%m-%d\")\n","\n","# Filter the sample data for clicks from yesterday\n","yesterday_data = [entry for entry in sample_data if entry[\"timestamp\"].startswith(yesterday_str)]\n","\n","# Create a dictionary to track IP addresses and their associated publisher_ids for yesterday's data\n","ip_publisher_counts = defaultdict(list)\n","\n","# Process the data for yesterday's clicks\n","for entry in yesterday_data:\n","    ip = entry[\"ip\"]\n","    publisher_id = entry[\"publisher_id\"]\n","    ip_publisher_counts[ip].append(publisher_id)\n","\n","# Find IP addresses with multiple clicks on the same publisher_id for yesterday\n","for ip, publisher_ids in ip_publisher_counts.items():\n","    unique_publisher_ids = set(publisher_ids)\n","    if len(unique_publisher_ids) > 1:\n","        print(f\"IP address {ip} clicked on multiple publisher_ids ({', '.join(map(str, unique_publisher_ids))}) yesterday\")\n"],"metadata":{"id":"alJj-LE8_wWi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Example3: Get data from your vendor's API and calculate the fraud rate.\n","\n","import requests\n","import pandas as pd\n","\n","# Define the API endpoint URL and any required headers\n","api_url = \"https://api.vendor.com/data\"\n","headers = {\n","    \"Authorization\": \"Bearer Your_API_Key\"\n","}\n","\n","try:\n","    # Make an HTTP GET request to the API\n","    response = requests.get(api_url, headers=headers)\n","\n","    if response.status_code == 200:\n","        # Convert the API response JSON data into a DataFrame\n","        data = response.json()\n","        df = pd.DataFrame(data)\n","\n","        # Group by publisher_id and sum the page views\n","        page_views_per_publisher = df.groupby('publisher_id')['page_views'].sum()\n","\n","        # Calculate the fraud percentage per publisher_id\n","        fraud_percentage = (df.groupby('publisher_id')['fraud'].sum() / page_views_per_publisher) * 100\n","\n","        # Print the results\n","        print(\"Page Views per Publisher:\")\n","        print(page_views_per_publisher)\n","\n","        print(\"\\nFraud Percentage per Publisher:\")\n","        print(fraud_percentage)\n","\n","    else:\n","        print(f\"Request failed with status code: {response.status_code}\")\n","\n","except requests.exceptions.RequestException as e:\n","    print(f\"Request error: {e}\")\n"],"metadata":{"id":"r-Q1uhiFCI31"},"execution_count":null,"outputs":[]}]}